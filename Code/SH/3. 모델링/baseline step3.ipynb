{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **라이브러리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.under_sampling import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.family'] = 'malgun gothic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **함수모음**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **모델링**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(model, X, y, test):    \n",
    "    model.fit(X, y)\n",
    "    pred = model.predict_proba(test)\n",
    "    pred = (pred[:,0] < 0.5)*1         # threshold 부도기업일 확률이 10% 이상이면 부도로 판단해라.\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **스코어**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(y_true, y_pred):\n",
    "    print('accuracy:', accuracy_score(y_true,y_pred))\n",
    "    print('f1-Score:', f1_score(y_true, y_pred, average='macro'))\n",
    "    print('Recall:',recall_score(y_true, y_pred, average='macro'))\n",
    "    print('Precision:',precision_score(y_true, y_pred, average='macro'))\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **데이터 나누기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['회사명', '거래소코드', '회계년도', '설비투자효율', '총자본투자효율', '부채구성비율', '비유동장기적합률',\n",
       "       '재고자산보유기간', '매출채권회수기간', '매입채무회전률', '경영자본회전률', '경영자본순이익률', '자기자본순이익률',\n",
       "       '자기자본증가율', '년', 'key', '부도'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = pd.read_csv(r'..\\..\\..\\Code\\JH\\data\\0y_finan.csv')\n",
    "# dataset1 = pd.read_csv(r'..\\..\\..\\Code\\JH\\data\\1y_finan.csv')\n",
    "# dataset2 = pd.read_csv(r'..\\..\\..\\Code\\JH\\data\\2y_finan.csv')\n",
    "\n",
    "# dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'..\\..\\..\\Code\\SH\\csv\\step3\\dataset_step3.csv', index_col=0)\n",
    "dataset1 = pd.read_csv(r'..\\..\\..\\Code\\SH\\csv\\step3\\dataset1_step3.csv')\n",
    "dataset2 = pd.read_csv(r'..\\..\\..\\Code\\SH\\csv\\step3\\dataset2_step3.csv')\n",
    "dataset3 = pd.read_csv(r'..\\..\\..\\Code\\SH\\csv\\step3\\dataset3_step3.csv')\n",
    "dataset4 = pd.read_csv(r'..\\..\\..\\Code\\SH\\csv\\step3\\dataset4_step3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splittrain(data):\n",
    "    subdata = data.sort_values(by='년').reset_index(drop=True)\n",
    "    data = subdata.loc[subdata['년'] < 2015]\n",
    "    return data\n",
    "\n",
    "def splittesst(data):\n",
    "    global test\n",
    "    subdata = data.sort_values(by='년').reset_index(drop=True)\n",
    "    test = subdata.loc[subdata['년'] >= 2015]\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ = splittrain(dataset)\n",
    "test_ = splittesst(dataset)\n",
    "dataset1_ = splittrain(dataset1)\n",
    "test1_ = splittesst(dataset1)\n",
    "dataset2_ = splittrain(dataset2)\n",
    "test2_ = splittesst(dataset2)\n",
    "dataset3_ = splittrain(dataset3)\n",
    "test3_ = splittesst(dataset3)\n",
    "dataset4_ = splittrain(dataset4)\n",
    "test4_ = splittesst(dataset4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_feature = ['회사명', '거래소코드', '회계년도','년', 'key', '부도']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_.drop(drop_feature, axis=1)\n",
    "X1 = dataset1_.drop(drop_feature, axis=1)\n",
    "X2 = dataset2_.drop(drop_feature, axis=1)\n",
    "X3 = dataset3_.drop(drop_feature, axis=1)\n",
    "X4 = dataset4_.drop(drop_feature, axis=1)\n",
    "\n",
    "y = dataset_['부도']\n",
    "y1 = dataset1_['부도']\n",
    "y2 = dataset2_['부도']\n",
    "y3 = dataset1_['부도']\n",
    "y4 = dataset2_['부도']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test =test_.drop(drop_feature, axis=1)\n",
    "X1_test =test1_.drop(drop_feature, axis=1)\n",
    "X2_test =test2_.drop(drop_feature, axis=1)\n",
    "X3_test =test3_.drop(drop_feature, axis=1)\n",
    "X4_test =test4_.drop(drop_feature, axis=1)\n",
    "\n",
    "y_test= test_['부도']\n",
    "y1_test =test1_['부도']\n",
    "y2_test =test2_['부도']\n",
    "y3_test =test3_['부도']\n",
    "y4_test =test4_['부도']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **YEAR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>설비투자효율</th>\n",
       "      <th>총자본투자효율</th>\n",
       "      <th>부채구성비율</th>\n",
       "      <th>비유동장기적합률</th>\n",
       "      <th>재고자산보유기간</th>\n",
       "      <th>매출채권회수기간</th>\n",
       "      <th>매입채무회전률</th>\n",
       "      <th>경영자본회전률</th>\n",
       "      <th>경영자본순이익률</th>\n",
       "      <th>...</th>\n",
       "      <th>회계처리위반</th>\n",
       "      <th>횡령배임</th>\n",
       "      <th>영업조업중단</th>\n",
       "      <th>종가변동률</th>\n",
       "      <th>출자목적_투자</th>\n",
       "      <th>출자목적_경영권</th>\n",
       "      <th>출자목적_영업이익</th>\n",
       "      <th>신종채권_운영</th>\n",
       "      <th>신종채권_시설</th>\n",
       "      <th>신종채권_기타</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>55.519145</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8284</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.472475</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21291</td>\n",
       "      <td>594.67</td>\n",
       "      <td>19.39</td>\n",
       "      <td>23.561363</td>\n",
       "      <td>31.87</td>\n",
       "      <td>14.717742</td>\n",
       "      <td>73.886640</td>\n",
       "      <td>31.71</td>\n",
       "      <td>1.16</td>\n",
       "      <td>12.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8293</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47.948294</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8298</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>49.133517</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18323</th>\n",
       "      <td>15236</td>\n",
       "      <td>7.16</td>\n",
       "      <td>1.80</td>\n",
       "      <td>56.507525</td>\n",
       "      <td>90.87</td>\n",
       "      <td>76.359833</td>\n",
       "      <td>74.338086</td>\n",
       "      <td>13.22</td>\n",
       "      <td>1.12</td>\n",
       "      <td>-6.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.419094</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18324</th>\n",
       "      <td>15415</td>\n",
       "      <td>53.08</td>\n",
       "      <td>8.19</td>\n",
       "      <td>30.932592</td>\n",
       "      <td>52.70</td>\n",
       "      <td>167.431193</td>\n",
       "      <td>190.104167</td>\n",
       "      <td>15.04</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-2.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077381</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18325</th>\n",
       "      <td>460</td>\n",
       "      <td>188.83</td>\n",
       "      <td>21.20</td>\n",
       "      <td>13.311606</td>\n",
       "      <td>53.77</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.811189</td>\n",
       "      <td>114.14</td>\n",
       "      <td>1.70</td>\n",
       "      <td>21.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18326</th>\n",
       "      <td>4629</td>\n",
       "      <td>226.27</td>\n",
       "      <td>19.03</td>\n",
       "      <td>11.804468</td>\n",
       "      <td>26.66</td>\n",
       "      <td>90.796020</td>\n",
       "      <td>54.477612</td>\n",
       "      <td>17.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>14.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.248227</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18327</th>\n",
       "      <td>650</td>\n",
       "      <td>37.88</td>\n",
       "      <td>17.95</td>\n",
       "      <td>69.818098</td>\n",
       "      <td>102.41</td>\n",
       "      <td>32.272325</td>\n",
       "      <td>77.167019</td>\n",
       "      <td>11.70</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18328 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  설비투자효율  총자본투자효율     부채구성비율  비유동장기적합률    재고자산보유기간  \\\n",
       "0               0    0.00     0.00  55.519145      0.00    0.000000   \n",
       "1            8284    0.00     0.00  46.472475      0.00    0.000000   \n",
       "2           21291  594.67    19.39  23.561363     31.87   14.717742   \n",
       "3            8293    0.00     0.00  47.948294      0.00    0.000000   \n",
       "4            8298    0.00     0.00  49.133517      0.00    0.000000   \n",
       "...           ...     ...      ...        ...       ...         ...   \n",
       "18323       15236    7.16     1.80  56.507525     90.87   76.359833   \n",
       "18324       15415   53.08     8.19  30.932592     52.70  167.431193   \n",
       "18325         460  188.83    21.20  13.311606     53.77    0.000000   \n",
       "18326        4629  226.27    19.03  11.804468     26.66   90.796020   \n",
       "18327         650   37.88    17.95  69.818098    102.41   32.272325   \n",
       "\n",
       "         매출채권회수기간  매입채무회전률  경영자본회전률  경영자본순이익률  ...  회계처리위반  횡령배임  영업조업중단  \\\n",
       "0        0.000000     0.00     0.00      0.00  ...     0.0   0.0     0.0   \n",
       "1        0.000000     0.00     0.00      0.00  ...     0.0   0.0     0.0   \n",
       "2       73.886640    31.71     1.16     12.76  ...     0.0   0.0     0.0   \n",
       "3        0.000000     0.00     0.00      0.00  ...     0.0   0.0     0.0   \n",
       "4        0.000000     0.00     0.00      0.00  ...     0.0   0.0     0.0   \n",
       "...           ...      ...      ...       ...  ...     ...   ...     ...   \n",
       "18323   74.338086    13.22     1.12     -6.03  ...     0.0   0.0     0.0   \n",
       "18324  190.104167    15.04     0.41     -2.02  ...     0.0   0.0     0.0   \n",
       "18325   63.811189   114.14     1.70     21.06  ...     0.0   0.0     0.0   \n",
       "18326   54.477612    17.84     0.83     14.51  ...     0.0   0.0     0.0   \n",
       "18327   77.167019    11.70     1.62      0.96  ...     0.0   0.0     0.0   \n",
       "\n",
       "          종가변동률  출자목적_투자  출자목적_경영권  출자목적_영업이익  신종채권_운영  신종채권_시설  신종채권_기타  \n",
       "0      0.000000      0.0       0.0        0.0      0.0      0.0      0.0  \n",
       "1      0.000000      0.0       0.0        0.0      0.0      0.0      0.0  \n",
       "2      0.000000      0.0       0.0        0.0      0.0      0.0      0.0  \n",
       "3      0.000000      0.0       0.0        0.0      0.0      0.0      0.0  \n",
       "4      0.000000      0.0       0.0        0.0      0.0      0.0      0.0  \n",
       "...         ...      ...       ...        ...      ...      ...      ...  \n",
       "18323 -0.419094      8.0       8.0        8.0      0.0      0.0      0.0  \n",
       "18324  0.077381      4.0       4.0        4.0      0.0      0.0      0.0  \n",
       "18325  0.451662      0.0       0.0        0.0      0.0      0.0      0.0  \n",
       "18326 -0.248227     50.0      50.0       50.0      0.0      0.0      0.0  \n",
       "18327  0.000000      1.0       1.0        1.0      0.0      0.0      0.0  \n",
       "\n",
       "[18328 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state = 488)\n",
    "X_train , y_train = RandomUnderSampler(random_state=0).fit_resample(X , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "LightGBMError",
     "evalue": "Do not support special JSON characters in feature name.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11024/1391617875.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mknn_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msvc_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mlgmb_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mcat_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmlp_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11024/1045647730.py\u001b[0m in \u001b[0;36mmodeling\u001b[1;34m(model, X, y, test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1\u001b[0m         \u001b[1;31m# threshold 부도기업일 확률이 10% 이상이면 부도로 판단해라.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    965\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m         super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n\u001b[0m\u001b[0;32m    968\u001b[0m                     \u001b[0meval_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m                     \u001b[0meval_class_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_class_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_init_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    746\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m    749\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;31m# construct booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[0mbooster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2603\u001b[0m                 )\n\u001b[0;32m   2604\u001b[0m             \u001b[1;31m# construct booster object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2605\u001b[1;33m             \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2606\u001b[0m             \u001b[1;31m# copy the parameters from train_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2607\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1813\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1814\u001b[0m                 \u001b[1;31m# create train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1815\u001b[1;33m                 self._lazy_init(self.data, label=self.label,\n\u001b[0m\u001b[0;32m   1816\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1817\u001b[0m                                 \u001b[0minit_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1571\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Wrong predictor type {type(predictor).__name__}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m         \u001b[1;31m# set feature names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1573\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_feature_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1575\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mset_feature_name\u001b[1;34m(self, feature_name)\u001b[0m\n\u001b[0;32m   2140\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Length of feature_name({len(feature_name)}) and num_feature({self.num_feature()}) don't match\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m             \u001b[0mc_feature_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2142\u001b[1;33m             _safe_call(_LIB.LGBM_DatasetSetFeatureNames(\n\u001b[0m\u001b[0;32m   2143\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2144\u001b[0m                 \u001b[0mc_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_feature_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \"\"\"\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLightGBMError\u001b[0m: Do not support special JSON characters in feature name."
     ]
    }
   ],
   "source": [
    "dt_clf = modeling(DecisionTreeClassifier(), X_train, y_train, X_test)\n",
    "rf_clf = modeling(RandomForestClassifier(),X_train, y_train, X_test)\n",
    "ada_clf = modeling(AdaBoostClassifier(), X_train, y_train, X_test)\n",
    "lg_clf = modeling(LogisticRegression(), X_train, y_train, X_test)\n",
    "knn_clf = modeling(KNeighborsClassifier(), X_train, y_train, X_test)\n",
    "svc_clf = modeling(SVC(probability=True), X_train, y_train, X_test)\n",
    "lgmb_clf = modeling(LGBMClassifier(), X_train, y_train, X_test)\n",
    "cat_clf = modeling(CatBoostClassifier(silent=True),X_train, y_train, X_test)\n",
    "mlp_clf = modeling(MLPClassifier(),X_train, y_train, X_test)\n",
    "xgb_clf = modeling(XGBClassifier(),X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8150218340611354\n",
      "f1-Score: 0.4755561426176922\n",
      "Recall: 0.8129300186262212\n",
      "Precision: 0.5131093933068802\n",
      "[[4636 1052]\n",
      " [   7   30]]\n"
     ]
    }
   ],
   "source": [
    "scoring(y_test , cat_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1YEAR AGO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, stratify=y1, random_state = 488)\n",
    "X1_train , y1_train = RandomUnderSampler(random_state=0).fit_resample(X1 , y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:40:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "dt_clf1 = modeling(DecisionTreeClassifier(), X1_train, y1_train, X1_test)\n",
    "rf_clf1 = modeling(RandomForestClassifier(),X1_train, y1_train, X1_test)\n",
    "ada_clf1 = modeling(AdaBoostClassifier(), X1_train, y1_train, X1_test)\n",
    "lg_clf1 = modeling(LogisticRegression(), X1_train, y1_train, X1_test)\n",
    "knn_clf1 = modeling(KNeighborsClassifier(), X1_train, y1_train, X1_test)\n",
    "svc_clf1 = modeling(SVC(probability=True), X1_train, y1_train, X1_test)\n",
    "lgmb_clf1 = modeling(LGBMClassifier(), X1_train, y1_train, X1_test)\n",
    "cat_clf1 = modeling(CatBoostClassifier(silent=True),X1_train, y1_train, X1_test)\n",
    "mlp_clf1 = modeling(MLPClassifier(),X1_train, y1_train, X1_test)\n",
    "xgb_clf1 = modeling(XGBClassifier(),X1_train, y1_train, X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7149344978165939\n",
      "f1-Score: 0.4296396899279321\n",
      "Recall: 0.7802448472741507\n",
      "Precision: 0.5061758691206544\n",
      "[[4071 1628]\n",
      " [   4   22]]\n"
     ]
    }
   ],
   "source": [
    "scoring(y1_test , cat_clf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2YEARS AGO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, stratify=y2, random_state = 488)\n",
    "X2_train , y2_train = RandomUnderSampler(random_state=0).fit_resample(X2 , y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:40:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "dt_clf2 = modeling(DecisionTreeClassifier(), X2_train, y2_train, X2_test)\n",
    "rf_clf2 = modeling(RandomForestClassifier(),X2_train, y2_train, X2_test)\n",
    "ada_clf2 = modeling(AdaBoostClassifier(), X2_train, y2_train, X2_test)\n",
    "lg_clf2 = modeling(LogisticRegression(), X2_train, y2_train, X2_test)\n",
    "knn_clf2 = modeling(KNeighborsClassifier(), X2_train, y2_train, X2_test)\n",
    "svc_clf2 = modeling(SVC(probability=True), X2_train, y2_train, X2_test)\n",
    "lgmb_clf2 = modeling(LGBMClassifier(), X2_train, y2_train, X2_test)\n",
    "cat_clf2 = modeling(CatBoostClassifier(silent=True),X2_train, y2_train, X2_test)\n",
    "mlp_clf2 = modeling(MLPClassifier(),X2_train, y2_train, X2_test)\n",
    "xgb_clf2 = modeling(XGBClassifier(),X2_train, y2_train, X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6620087336244541\n",
      "f1-Score: 0.40563042489748785\n",
      "Recall: 0.7058501314636284\n",
      "Precision: 0.5031946654697298\n",
      "[[3775 1930]\n",
      " [   5   15]]\n"
     ]
    }
   ],
   "source": [
    "scoring(y2_test , cat_clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3YEARS AGO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:51:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, stratify=y3, random_state = 488)\n",
    "X3_train , y3_train = RandomUnderSampler(random_state=0).fit_resample(X3 , y3)\n",
    "\n",
    "dt_clf3 = modeling(DecisionTreeClassifier(), X3_train, y3_train, X3_test)\n",
    "rf_clf3 = modeling(RandomForestClassifier(),X3_train, y3_train, X3_test)\n",
    "ada_clf3 = modeling(AdaBoostClassifier(), X3_train, y3_train, X3_test)\n",
    "lg_clf3 = modeling(LogisticRegression(), X3_train, y3_train, X3_test)\n",
    "knn_clf3 = modeling(KNeighborsClassifier(), X3_train, y3_train, X3_test)\n",
    "svc_clf3 = modeling(SVC(probability=True), X3_train, y3_train, X3_test)\n",
    "lgmb_clf3 = modeling(LGBMClassifier(), X3_train, y3_train, X3_test)\n",
    "cat_clf3 = modeling(CatBoostClassifier(silent=True),X3_train, y3_train, X3_test)\n",
    "mlp_clf3 = modeling(MLPClassifier(),X3_train, y3_train, X3_test)\n",
    "xgb_clf3 = modeling(XGBClassifier(),X3_train, y3_train, X3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6000705550329257\n",
      "f1-Score: 0.3815436851040985\n",
      "Recall: 0.6634238739657226\n",
      "Precision: 0.5026284465997967\n",
      "[[5079 3392]\n",
      " [   9   24]]\n"
     ]
    }
   ],
   "source": [
    "scoring(y3_test , cat_clf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4YEARS AGO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:52:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.2, stratify=y4, random_state = 488)\n",
    "X4_train , y4_train = RandomUnderSampler(random_state=0).fit_resample(X4 , y4)\n",
    "\n",
    "dt_clf4 = modeling(DecisionTreeClassifier(), X4_train, y4_train, X4_test)\n",
    "rf_clf4 = modeling(RandomForestClassifier(),X4_train, y4_train, X4_test)\n",
    "ada_clf4 = modeling(AdaBoostClassifier(), X4_train, y4_train, X4_test)\n",
    "lg_clf4 = modeling(LogisticRegression(), X4_train, y4_train, X4_test)\n",
    "knn_clf4 = modeling(KNeighborsClassifier(), X4_train, y4_train, X4_test)\n",
    "svc_clf4 = modeling(SVC(probability=True), X4_train, y4_train, X4_test)\n",
    "lgmb_clf4 = modeling(LGBMClassifier(), X4_train, y4_train, X4_test)\n",
    "cat_clf4 = modeling(CatBoostClassifier(silent=True),X4_train, y4_train, X4_test)\n",
    "mlp_clf4 = modeling(MLPClassifier(),X4_train, y4_train, X4_test)\n",
    "xgb_clf4 = modeling(XGBClassifier(),X4_train, y4_train, X4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.644167450611477\n",
      "f1-Score: 0.39615646094722873\n",
      "Recall: 0.6402756639729053\n",
      "Precision: 0.5015777129719637\n",
      "[[5464 3018]\n",
      " [   8   14]]\n"
     ]
    }
   ],
   "source": [
    "scoring(y4_test , cat_clf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 16 artists>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(ajX_train.columns, model.feature_importances_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "71b59b5ba49ad06bb2a011e750699e3983d230921f30bf7f37eb3a01ae69aa26"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
