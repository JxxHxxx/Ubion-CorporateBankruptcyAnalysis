{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'C:\\Users\\JH\\Desktop\\Final\\CBA\\Data\\데이터정리중\\0020년도데이터가다있는데이터.csv', index_col=0)\n",
    "dataset.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "회사명          0\n",
       "거래소코드        0\n",
       "회계년도         0\n",
       "당좌자산(요약)     0\n",
       "당기순이익(요약)    0\n",
       "자기자본증가율      0\n",
       "매출액총이익률      0\n",
       "유동비율         0\n",
       "부도           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.fillna(0,inplace=True)\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['자기자본증가율'] = dataset['자기자본증가율'].astype(str)\n",
    "dataset['당좌자산(요약)'] = dataset['당좌자산(요약)'].astype(str)\n",
    "dataset['당기순이익(요약)'] = dataset['당기순이익(요약)'].astype(str)\n",
    "dataset['매출액총이익률'] = dataset['매출액총이익률'].astype(str)\n",
    "dataset['유동비율'] = dataset['유동비율'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "lia = []\n",
    "\n",
    "a = dataset.loc[dataset['회사명'] == '(주)삼진엘앤디']['자기자본증가율'].reset_index(drop=True)[i]\n",
    "lia.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [['nice great best amazing', 'stop lies'] ,['pitiful nerd', 'excellent work'], ['supreme quality', 'bad'], ['highly respectable', 'fuck that']]\n",
    "y_train = [1, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [['5917.0', '7680.0', '11683.0', '12165.0', '11842.0','1208.0', '1440.0', '1749.0', '890.0', '1593.0','0.0', '17.46', '72.46', '-2.53', '5.22'],\n",
    "             ['5506.0', '14941.0', '17114.0', '20607.0', '27944.0','615.0', '1446.0', '3040.0', '5883.0', '6305.0','0.0', '49.98', '14.59', '23.22', '61.17']]\n",
    "y_train = [1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 1, 26, 27, 28, 29]]\n"
     ]
    }
   ],
   "source": [
    "X_encoded = tokenizer.texts_to_sequences(sentences)\n",
    "print(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(l) for l in X_encoded)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  3  4  5  6  7  8  9 10 11  1 12 13 14 15]\n",
      " [16 17 18 19 20 21 22 23 24 25  1 26 27 28 29]]\n"
     ]
    }
   ],
   "source": [
    "X_train = pad_sequences(X_encoded, maxlen=max_len, padding='post')\n",
    "y_train = np.array(y_train)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 15\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "\n",
    "embedding_dim = 4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 1s - loss: 0.6865 - acc: 1.0000\n",
      "Epoch 2/100\n",
      "1/1 - 0s - loss: 0.6818 - acc: 1.0000\n",
      "Epoch 3/100\n",
      "1/1 - 0s - loss: 0.6772 - acc: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 - 0s - loss: 0.6726 - acc: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 - 0s - loss: 0.6679 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 - 0s - loss: 0.6634 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 - 0s - loss: 0.6588 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "1/1 - 0s - loss: 0.6543 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 - 0s - loss: 0.6498 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 - 0s - loss: 0.6452 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 - 0s - loss: 0.6408 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 - 0s - loss: 0.6363 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 - 0s - loss: 0.6318 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 - 0s - loss: 0.6273 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 - 0s - loss: 0.6229 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 - 0s - loss: 0.6184 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 - 0s - loss: 0.6140 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 - 0s - loss: 0.6095 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 - 0s - loss: 0.6051 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 - 0s - loss: 0.6006 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 - 0s - loss: 0.5962 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 - 0s - loss: 0.5917 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 - 0s - loss: 0.5873 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 - 0s - loss: 0.5828 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 - 0s - loss: 0.5783 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 - 0s - loss: 0.5738 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 - 0s - loss: 0.5693 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 - 0s - loss: 0.5647 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 - 0s - loss: 0.5602 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 - 0s - loss: 0.5556 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 - 0s - loss: 0.5510 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 - 0s - loss: 0.5464 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 - 0s - loss: 0.5418 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 - 0s - loss: 0.5372 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 - 0s - loss: 0.5326 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 - 0s - loss: 0.5279 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 - 0s - loss: 0.5232 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 - 0s - loss: 0.5185 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 - 0s - loss: 0.5138 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 - 0s - loss: 0.5090 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 - 0s - loss: 0.5043 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 - 0s - loss: 0.4995 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 - 0s - loss: 0.4947 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 - 0s - loss: 0.4899 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 - 0s - loss: 0.4851 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 - 0s - loss: 0.4802 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 - 0s - loss: 0.4754 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 - 0s - loss: 0.4705 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 - 0s - loss: 0.4656 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 - 0s - loss: 0.4607 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 - 0s - loss: 0.4558 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 - 0s - loss: 0.4509 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 - 0s - loss: 0.4460 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 - 0s - loss: 0.4411 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 - 0s - loss: 0.4362 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 - 0s - loss: 0.4313 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 - 0s - loss: 0.4263 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 - 0s - loss: 0.4214 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 - 0s - loss: 0.4165 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 - 0s - loss: 0.4115 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 - 0s - loss: 0.4066 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 - 0s - loss: 0.4017 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 - 0s - loss: 0.3968 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 - 0s - loss: 0.3919 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 - 0s - loss: 0.3870 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 - 0s - loss: 0.3821 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 - 0s - loss: 0.3772 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 - 0s - loss: 0.3724 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 - 0s - loss: 0.3675 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 - 0s - loss: 0.3627 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 - 0s - loss: 0.3579 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 - 0s - loss: 0.3531 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 - 0s - loss: 0.3484 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 - 0s - loss: 0.3437 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 - 0s - loss: 0.3389 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 - 0s - loss: 0.3343 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 - 0s - loss: 0.3296 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 - 0s - loss: 0.3250 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 - 0s - loss: 0.3204 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 - 0s - loss: 0.3158 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 - 0s - loss: 0.3113 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 - 0s - loss: 0.3068 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 - 0s - loss: 0.3023 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 - 0s - loss: 0.2979 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 - 0s - loss: 0.2935 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 - 0s - loss: 0.2891 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 - 0s - loss: 0.2848 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 - 0s - loss: 0.2805 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 - 0s - loss: 0.2763 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 - 0s - loss: 0.2721 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 - 0s - loss: 0.2680 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 - 0s - loss: 0.2639 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 - 0s - loss: 0.2598 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 - 0s - loss: 0.2558 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 - 0s - loss: 0.2518 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 - 0s - loss: 0.2479 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 - 0s - loss: 0.2440 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 - 0s - loss: 0.2402 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 - 0s - loss: 0.2364 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 - 0s - loss: 0.2326 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x256fcd6fdf0>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10, 64)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(1000, 64, input_length=10))\n",
    "# The model will take as input an integer matrix of size (batch,\n",
    "# input_length), and the largest integer (i.e. word index) in the input\n",
    "# should be no larger than 999 (vocabulary size).\n",
    "# Now model.output_shape is (None, 10, 64), where `None` is the batch\n",
    "# dimension.\n",
    "input_array = np.random.randint(1000, size=(32, 10))\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "print(output_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "71b59b5ba49ad06bb2a011e750699e3983d230921f30bf7f37eb3a01ae69aa26"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
