{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **라이브러리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.under_sampling import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.family'] = 'malgun gothic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **함수모음**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **모델링**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(model, X, y, test):    \n",
    "    model.fit(X, y)\n",
    "    pred = model.predict_proba(test)\n",
    "    pred = (pred[:,0] < 0.5)*1         # threshold 부도기업일 확률이 10% 이상이면 부도로 판단해라.\n",
    "    return pred\n",
    "\n",
    "def modeling_(model, X, y, test):    \n",
    "    model.fit(X, y)\n",
    "    pred = model.predict_proba(test)         # threshold 부도기업일 확률이 10% 이상이면 부도로 판단해라.\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **스코어**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(y_true, y_pred):\n",
    "    print('accuracy:', accuracy_score(y_true,y_pred))\n",
    "    print('f1-Score:', f1_score(y_true, y_pred, average='macro'))\n",
    "    print('Recall:',recall_score(y_true, y_pred, average='macro'))\n",
    "    print('Precision:',precision_score(y_true, y_pred, average='macro'))\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **데이터 나누기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['회사명', '거래소코드', '회계년도', '설비투자효율', '총자본투자효율', '부채구성비율', '비유동장기적합률',\n",
       "       '재고자산보유기간', '매출채권회수기간', '매입채무회전률', '경영자본회전률', '경영자본순이익률', '자기자본순이익률',\n",
       "       '자기자본증가율', '년', 'key', '부도', '대표이사_변경', '최대주주_변경', '회계처리위반', '횡령배임',\n",
       "       '신종채권', '영업조업중단', '종가변동률'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'C:\\Users\\JH\\Desktop\\Final\\Ubion-CorporateBankruptcyAnalysis\\Code\\JH\\data\\0y_finan+step1.csv')\n",
    "dataset1 = pd.read_csv(r'C:\\Users\\JH\\Desktop\\Final\\Ubion-CorporateBankruptcyAnalysis\\Code\\JH\\data\\1y_finan+step1.csv')\n",
    "dataset2 = pd.read_csv(r'C:\\Users\\JH\\Desktop\\Final\\Ubion-CorporateBankruptcyAnalysis\\Code\\JH\\data\\2y_finan+step1.csv')\n",
    "dataset3 = pd.read_csv(r'C:\\Users\\JH\\Desktop\\Final\\Ubion-CorporateBankruptcyAnalysis\\Code\\JH\\data\\3y_finan+step1.csv')\n",
    "dataset4 = pd.read_csv(r'C:\\Users\\JH\\Desktop\\Final\\Ubion-CorporateBankruptcyAnalysis\\Code\\JH\\data\\4y_finan+step1.csv')\n",
    "\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splittrain(data):\n",
    "    subdata = data.sort_values(by='년').reset_index(drop=True)\n",
    "    data = subdata.loc[subdata['년'] < 2015]\n",
    "    return data\n",
    "\n",
    "def splittesst(data):\n",
    "    global test\n",
    "    subdata = data.sort_values(by='년').reset_index(drop=True)\n",
    "    test = subdata.loc[subdata['년'] >= 2015]\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ = splittrain(dataset)\n",
    "test_ = splittesst(dataset)\n",
    "dataset1_ = splittrain(dataset1)\n",
    "test1_ = splittesst(dataset1)\n",
    "dataset2_ = splittrain(dataset2)\n",
    "test2_ = splittesst(dataset2)\n",
    "dataset3_ = splittrain(dataset3)\n",
    "test3_ = splittesst(dataset3)\n",
    "dataset4_ = splittrain(dataset4)\n",
    "test4_ = splittesst(dataset4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_feature = ['회사명', '거래소코드', '회계년도','년', 'key', '부도']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_.drop(drop_feature, axis=1)\n",
    "X1 = dataset1_.drop(drop_feature, axis=1)\n",
    "X2 = dataset2_.drop(drop_feature, axis=1)\n",
    "X3 = dataset3_.drop(drop_feature, axis=1)\n",
    "X4 = dataset4_.drop(drop_feature, axis=1)\n",
    "\n",
    "y = dataset_['부도']\n",
    "y1 = dataset1_['부도']\n",
    "y2 = dataset2_['부도']\n",
    "y3 = dataset3_['부도']\n",
    "y4 = dataset4_['부도']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test =test_.drop(drop_feature, axis=1)\n",
    "X1_test =test1_.drop(drop_feature, axis=1)\n",
    "X2_test =test2_.drop(drop_feature, axis=1)\n",
    "X3_test =test3_.drop(drop_feature, axis=1)\n",
    "X4_test =test4_.drop(drop_feature, axis=1)\n",
    "\n",
    "y_test= test_['부도']\n",
    "y1_test =test1_['부도']\n",
    "y2_test =test2_['부도']\n",
    "y3_test =test3_['부도']\n",
    "y4_test =test4_['부도']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **YEAR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state = 488)\n",
    "X_train , y_train = RandomUnderSampler(random_state=0).fit_resample(X , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:59:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "dt_clf = modeling(DecisionTreeClassifier(), X_train, y_train, X_test)\n",
    "rf_clf = modeling(RandomForestClassifier(),X_train, y_train, X_test)\n",
    "ada_clf = modeling(AdaBoostClassifier(), X_train, y_train, X_test)\n",
    "lg_clf = modeling(LogisticRegression(), X_train, y_train, X_test)\n",
    "knn_clf = modeling(KNeighborsClassifier(), X_train, y_train, X_test)\n",
    "svc_clf = modeling(SVC(probability=True), X_train, y_train, X_test)\n",
    "lgmb_clf = modeling(LGBMClassifier(), X_train, y_train, X_test)\n",
    "cat_clf = modeling(CatBoostClassifier(silent=True),X_train, y_train, X_test)\n",
    "mlp_clf = modeling(MLPClassifier(),X_train, y_train, X_test)\n",
    "xgb_clf = modeling(XGBClassifier(),X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8233772342427094\n",
      "f1-Score: 0.4841939652387413\n",
      "Recall: 0.9111347769494734\n",
      "Precision: 0.5170418006430868\n",
      "[[6949 1502]\n",
      " [   0   53]]\n"
     ]
    }
   ],
   "source": [
    "scoring(y_test , cat_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1YEAR AGO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, stratify=y1, random_state = 488)\n",
    "X1_train , y1_train = RandomUnderSampler(random_state=0).fit_resample(X1 , y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:00:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:55:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "dt_clf1 = modeling(DecisionTreeClassifier(), X1_train, y1_train, X1_test)\n",
    "rf_clf1 = modeling(RandomForestClassifier(),X1_train, y1_train, X1_test)\n",
    "ada_clf1 = modeling(AdaBoostClassifier(), X1_train, y1_train, X1_test)\n",
    "lg_clf1 = modeling(LogisticRegression(), X1_train, y1_train, X1_test)\n",
    "knn_clf1 = modeling(KNeighborsClassifier(), X1_train, y1_train, X1_test)\n",
    "svc_clf1 = modeling(SVC(probability=True), X1_train, y1_train, X1_test)\n",
    "lgmb_clf1 = modeling(LGBMClassifier(), X1_train, y1_train, X1_test)\n",
    "cat_clf1 = modeling(CatBoostClassifier(silent=True),X1_train, y1_train, X1_test)\n",
    "mlp_clf1 = modeling(MLPClassifier(),X1_train, y1_train, X1_test)\n",
    "xgb_clf1 = modeling(XGBClassifier(),X1_train, y1_train, X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.993414863593603\n",
      "f1-Score: 0.49834827748938176\n",
      "Recall: 0.49952696310312206\n",
      "Precision: 0.4971751412429379\n",
      "[[8448    8]\n",
      " [  48    0]]\n"
     ]
    }
   ],
   "source": [
    "scoring(y1_test , cat_clf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2YEARS AGO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, stratify=y2, random_state = 488)\n",
    "X2_train , y2_train = RandomUnderSampler(random_state=0).fit_resample(X2 , y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:00:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "dt_clf2 = modeling(DecisionTreeClassifier(), X2_train, y2_train, X2_test)\n",
    "rf_clf2 = modeling(RandomForestClassifier(),X2_train, y2_train, X2_test)\n",
    "ada_clf2 = modeling(AdaBoostClassifier(), X2_train, y2_train, X2_test)\n",
    "lg_clf2 = modeling(LogisticRegression(), X2_train, y2_train, X2_test)\n",
    "knn_clf2 = modeling(KNeighborsClassifier(), X2_train, y2_train, X2_test)\n",
    "svc_clf2 = modeling(SVC(probability=True), X2_train, y2_train, X2_test)\n",
    "lgmb_clf2 = modeling(LGBMClassifier(), X2_train, y2_train, X2_test)\n",
    "cat_clf2 = modeling(CatBoostClassifier(silent=True),X2_train, y2_train, X2_test)\n",
    "mlp_clf2 = modeling(MLPClassifier(),X2_train, y2_train, X2_test)\n",
    "xgb_clf2 = modeling(XGBClassifier(),X2_train, y2_train, X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6546331138287864\n",
      "f1-Score: 0.4070637576519673\n",
      "Recall: 0.7269298971509635\n",
      "Precision: 0.5052606001256961\n",
      "[[5531 2928]\n",
      " [   9   36]]\n"
     ]
    }
   ],
   "source": [
    "scoring(y2_test , cat_clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3YEARS AGO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:00:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, stratify=y3, random_state = 488)\n",
    "X3_train , y3_train = RandomUnderSampler(random_state=0).fit_resample(X3 , y3)\n",
    "\n",
    "dt_clf3 = modeling(DecisionTreeClassifier(), X3_train, y3_train, X3_test)\n",
    "rf_clf3 = modeling(RandomForestClassifier(),X3_train, y3_train, X3_test)\n",
    "ada_clf3 = modeling(AdaBoostClassifier(), X3_train, y3_train, X3_test)\n",
    "lg_clf3 = modeling(LogisticRegression(), X3_train, y3_train, X3_test)\n",
    "knn_clf3 = modeling(KNeighborsClassifier(), X3_train, y3_train, X3_test)\n",
    "svc_clf3 = modeling(SVC(probability=True), X3_train, y3_train, X3_test)\n",
    "lgmb_clf3 = modeling(LGBMClassifier(), X3_train, y3_train, X3_test)\n",
    "cat_clf3 = modeling(CatBoostClassifier(silent=True),X3_train, y3_train, X3_test)\n",
    "mlp_clf3 = modeling(MLPClassifier(),X3_train, y3_train, X3_test)\n",
    "xgb_clf3 = modeling(XGBClassifier(),X3_train, y3_train, X3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.613005644402634\n",
      "f1-Score: 0.38597156242132435\n",
      "Recall: 0.6246391431729644\n",
      "Precision: 0.5020288589197122\n",
      "[[5192 3279]\n",
      " [  12   21]]\n"
     ]
    }
   ],
   "source": [
    "scoring(y3_test , cat_clf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4YEARS AGO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:00:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.2, stratify=y4, random_state = 488)\n",
    "X4_train , y4_train = RandomUnderSampler(random_state=0).fit_resample(X4 , y4)\n",
    "\n",
    "dt_clf4 = modeling(DecisionTreeClassifier(), X4_train, y4_train, X4_test)\n",
    "rf_clf4 = modeling(RandomForestClassifier(),X4_train, y4_train, X4_test)\n",
    "ada_clf4 = modeling(AdaBoostClassifier(), X4_train, y4_train, X4_test)\n",
    "lg_clf4 = modeling(LogisticRegression(), X4_train, y4_train, X4_test)\n",
    "knn_clf4 = modeling(KNeighborsClassifier(), X4_train, y4_train, X4_test)\n",
    "svc_clf4 = modeling(SVC(probability=True), X4_train, y4_train, X4_test)\n",
    "lgmb_clf4 = modeling(LGBMClassifier(), X4_train, y4_train, X4_test)\n",
    "cat_clf4 = modeling(CatBoostClassifier(silent=True),X4_train, y4_train, X4_test)\n",
    "mlp_clf4 = modeling(MLPClassifier(),X4_train, y4_train, X4_test)\n",
    "xgb_clf4 = modeling(XGBClassifier(),X4_train, y4_train, X4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6440498588899342\n",
      "f1-Score: 0.39518306798824304\n",
      "Recall: 0.5722117425135581\n",
      "Precision: 0.5008127811295323\n",
      "[[5466 3016]\n",
      " [  11   11]]\n"
     ]
    }
   ],
   "source": [
    "scoring(y4_test , cat_clf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ajX_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26432/3150341982.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0majX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ajX_train' is not defined"
     ]
    }
   ],
   "source": [
    "plt.barh(ajX_train.columns, model.feature_importances_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "71b59b5ba49ad06bb2a011e750699e3983d230921f30bf7f37eb3a01ae69aa26"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
