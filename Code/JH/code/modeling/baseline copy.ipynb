{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **라이브러리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.under_sampling import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, confusion_matrix, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.family'] = 'malgun gothic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **함수모음**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **모델링**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(model, X, y, test):    \n",
    "    model.fit(X, y)\n",
    "    pred = model.predict_proba(test)\n",
    "    pred = (pred[:,0] < 0.5)*1         # threshold 부도기업일 확률이 10% 이상이면 부도로 판단해라.\n",
    "    return pred\n",
    "\n",
    "def modeling_(model, X, y, test):    \n",
    "    model.fit(X, y)\n",
    "    pred = model.predict_proba(test)\n",
    "    pred = (pred[:,0] < optimal_threshold)*1         # threshold 부도기업일 확률이 10% 이상이면 부도로 판단해라.\n",
    "    return pred\n",
    "\n",
    "######################################## Split train, test\n",
    "def splittrain(data):\n",
    "    subdata = data.sort_values(by='년').reset_index(drop=True)\n",
    "    data = subdata.loc[subdata['년'] < 2015]\n",
    "    return data\n",
    "\n",
    "def splittesst(data):\n",
    "    global test\n",
    "    subdata = data.sort_values(by='년').reset_index(drop=True)\n",
    "    test = subdata.loc[subdata['년'] >= 2015]\n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **스코어**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(y_true, y_pred):\n",
    "    print('accuracy:', accuracy_score(y_true,y_pred))\n",
    "    print('f1-Score:', f1_score(y_true, y_pred, average='weighted'))\n",
    "    print('Recall:',recall_score(y_true, y_pred, average='weighted'))\n",
    "    print('Precision:',precision_score(y_true, y_pred, average='weighted'))\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **귀찮다 귀찮아**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **데이터 나누기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **재무데이터**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['회사명', '거래소코드', '회계년도', '순운전자본비율', '총자본순이익률', '경영자본순이익률', '경영자본회전률',\n",
       "       '매입채무회전률', '설비투자효율', '총자본투자효율', '자기자본증가율', '부채구성비율', '재고자산보유기간',\n",
       "       '매출채권회수기간', '최대주주_변경', '회계처리위반', '횡령배임', '신종채권', '영업조업중단', '출자목적_투자',\n",
       "       '출자목적_경영권', '출자목적_영업이익', '외국인_주식분포비율', '종가', '종가변동률', '년', 'key', '부도',\n",
       "       '신종채권_운영', '신종채권_시설', '신종채권_기타'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'C:\\Users\\JH\\Desktop\\Final\\Ubion-CorporateBankruptcyAnalysis\\Code\\JH\\data\\ver2\\0years_ago.csv')\n",
    "dataset1 = pd.read_csv(r'C:\\Users\\JH\\Desktop\\Final\\Ubion-CorporateBankruptcyAnalysis\\Code\\JH\\data\\ver2\\1years_ago.csv')\n",
    "dataset2 = pd.read_csv(r'C:\\Users\\JH\\Desktop\\Final\\Ubion-CorporateBankruptcyAnalysis\\Code\\JH\\data\\ver2\\2years_ago.csv')\n",
    "dataset3 = pd.read_csv(r'C:\\Users\\JH\\Desktop\\Final\\Ubion-CorporateBankruptcyAnalysis\\Code\\JH\\data\\ver2\\3years_ago.csv')\n",
    "dataset4 = pd.read_csv(r'C:\\Users\\JH\\Desktop\\Final\\Ubion-CorporateBankruptcyAnalysis\\Code\\JH\\data\\ver2\\4years_ago.csv')\n",
    "\n",
    "drop_features = ['회사명', '거래소코드', '회계년도','년', 'key', '부도','최대주주_변경', '회계처리위반', '횡령배임', '신종채권', '영업조업중단',\n",
    "'출자목적_투자','출자목적_경영권', '출자목적_영업이익','외국인_주식분포비율', '종가','종가변동률','신종채권_운영', '신종채권_시설', '신종채권_기타']\n",
    "\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **재무데이터 + 비재무데이터**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['회사명', '거래소코드', '회계년도', '설비투자효율', '총자본투자효율', '부채구성비율', '비유동장기적합률',\n",
       "       '재고자산보유기간', '매출채권회수기간', '매입채무회전률', '경영자본회전률', '경영자본순이익률', '자기자본순이익률',\n",
       "       '자기자본증가율', '년', 'key', '부도', '대표이사_변경', '최대주주_변경', '회계처리위반', '횡령배임',\n",
       "       '영업조업중단', '종가변동률', '출자목적_투자', '출자목적_경영권', '출자목적_영업이익', '신종채권_운영',\n",
       "       '신종채권_시설', '신종채권_기타'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ajdataset = pd.read_csv(r'C:\\Users\\JH\\Desktop\\Final\\Ubion-CorporateBankruptcyAnalysis\\Code\\JH\\data\\ver2\\0years_agostep3.csv')\n",
    "ajdataset1 = pd.read_csv(r'C:\\Users\\JH\\Desktop\\Final\\Ubion-CorporateBankruptcyAnalysis\\Code\\JH\\data\\ver2\\1years_agostep3.csv')\n",
    "ajdataset2 = pd.read_csv(r'C:\\Users\\JH\\Desktop\\Final\\Ubion-CorporateBankruptcyAnalysis\\Code\\JH\\data\\ver2\\2years_agostep3.csv')\n",
    "ajdataset3 = pd.read_csv(r'C:\\Users\\JH\\Desktop\\Final\\Ubion-CorporateBankruptcyAnalysis\\Code\\JH\\data\\ver2\\3years_agostep3.csv')\n",
    "ajdataset4 = pd.read_csv(r'C:\\Users\\JH\\Desktop\\Final\\Ubion-CorporateBankruptcyAnalysis\\Code\\JH\\data\\ver2\\4years_agostep3.csv')\n",
    "\n",
    "drop_feature = ['회사명', '거래소코드', '회계년도','년', 'key', '부도']\n",
    "\n",
    "ajdataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ = splittrain(dataset)\n",
    "test_ = splittesst(dataset)\n",
    "dataset1_ = splittrain(dataset1)\n",
    "test1_ = splittesst(dataset1)\n",
    "dataset2_ = splittrain(dataset2)\n",
    "test2_ = splittesst(dataset2)\n",
    "dataset3_ = splittrain(dataset3)\n",
    "test3_ = splittesst(dataset3)\n",
    "dataset4_ = splittrain(dataset4)\n",
    "test4_ = splittesst(dataset4)\n",
    "\n",
    "ajdataset_ = splittrain(ajdataset)\n",
    "ajtest_ = splittesst(ajdataset)\n",
    "ajdataset1_ = splittrain(ajdataset1)\n",
    "ajtest1_ = splittesst(ajdataset1)\n",
    "ajdataset2_ = splittrain(ajdataset2)\n",
    "ajtest2_ = splittesst(ajdataset2)\n",
    "ajdataset3_ = splittrain(ajdataset3)\n",
    "ajtest3_ = splittesst(ajdataset3)\n",
    "ajdataset4_ = splittrain(ajdataset4)\n",
    "ajtest4_ = splittesst(ajdataset4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **세트 1. 재무데이터 train,test 분리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8381, 11) (8381,)\n",
      "(8355,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset_.drop(drop_features, axis=1)\n",
    "X1 = dataset1_.drop(drop_features, axis=1)\n",
    "X2 = dataset2_.drop(drop_features, axis=1)\n",
    "X3 = dataset3_.drop(drop_features, axis=1)\n",
    "X4 = dataset4_.drop(drop_features, axis=1)\n",
    "\n",
    "y = dataset_['부도']\n",
    "y1 = dataset1_['부도']\n",
    "y2 = dataset2_['부도']\n",
    "y3 = dataset3_['부도']\n",
    "y4 = dataset4_['부도']\n",
    "\n",
    "X_test =test_.drop(drop_features, axis=1)\n",
    "X1_test =test1_.drop(drop_features, axis=1)\n",
    "X2_test =test2_.drop(drop_features, axis=1)\n",
    "X3_test =test3_.drop(drop_features, axis=1)\n",
    "X4_test =test4_.drop(drop_features, axis=1)\n",
    "\n",
    "y_test= test_['부도']\n",
    "y1_test =test1_['부도']\n",
    "y2_test =test2_['부도']\n",
    "y3_test =test3_['부도']\n",
    "y4_test =test4_['부도']\n",
    "\n",
    "print(X3_test.shape, y3_test.shape)\n",
    "print(dt_clf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **세트2 재무 + 비재무데이터 train, test 분리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8381, 23) (8381,)\n",
      "(8355,)\n"
     ]
    }
   ],
   "source": [
    "ajX = ajdataset_.drop(drop_feature, axis=1)\n",
    "ajX1 = ajdataset1_.drop(drop_feature, axis=1)\n",
    "ajX2 = ajdataset2_.drop(drop_feature, axis=1)\n",
    "ajX3 = ajdataset3_.drop(drop_feature, axis=1)\n",
    "ajX4 = ajdataset4_.drop(drop_feature, axis=1)\n",
    "\n",
    "ajy = ajdataset_['부도']\n",
    "ajy1 = ajdataset1_['부도']\n",
    "ajy2 = ajdataset2_['부도']\n",
    "ajy3 = ajdataset3_['부도']\n",
    "ajy4 = ajdataset4_['부도']\n",
    "\n",
    "ajX_test =ajtest_.drop(drop_feature, axis=1)\n",
    "ajX1_test =ajtest1_.drop(drop_feature, axis=1)\n",
    "ajX2_test =ajtest2_.drop(drop_feature, axis=1)\n",
    "ajX3_test =ajtest3_.drop(drop_feature, axis=1)\n",
    "ajX4_test =ajtest4_.drop(drop_feature, axis=1)\n",
    "\n",
    "ajy_test= ajtest_['부도']\n",
    "ajy1_test =ajtest1_['부도']\n",
    "ajy2_test =ajtest2_['부도']\n",
    "ajy3_test =ajtest3_['부도']\n",
    "ajy4_test =ajtest4_['부도']\n",
    "\n",
    "print(ajX3_test.shape, ajy3_test.shape)\n",
    "print(dt_clf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **YEAR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **데이터 검증 및 언더샘플링**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "mdn = ['Decision Tree','Random Forest','Adaboost','logistic', 'KNN','SVC','lightGBM','Catboost','MLP','Xgboost']\n",
    "\n",
    "def run_skfold(feature, target):\n",
    "    X, y = RandomUnderSampler(random_state=1).fit_resample(feature, target) # RandomUnderSampling\n",
    "    skf = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "    arr = [] # Validation Set's Accuracy\n",
    "    models = [DecisionTreeClassifier(),RandomForestClassifier(),AdaBoostClassifier(),LogisticRegression(),KNeighborsClassifier(),\n",
    "    SVC(probability=True),LGBMClassifier(),CatBoostClassifier(silent=True),MLPClassifier(),XGBClassifier()]\n",
    "\n",
    "    for model in models:\n",
    "        val_pred = 0\n",
    "        for train_index, val_index in skf.split(X,y):\n",
    "            # print(\"TRAIN:\", train_index, \"TEST:\", val_index)\n",
    "            X_train, X_val = X[train_index], X[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "            val_pred += accuracy_score(y_val, modeling(model, X_train, y_train, X_val))\n",
    "        arr.append(val_pred/4)\n",
    "    return arr # each models accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:29:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# 1,2,3,4 숫자구분해줘야함\n",
    "X = np.array(X1)\n",
    "ajX = np.array(ajX1)\n",
    "\n",
    "y = y1\n",
    "ajy = ajy1\n",
    "\n",
    "ajX_test = ajX1_test\n",
    "X_test = X1_test\n",
    "\n",
    "y_test = y1_test\n",
    "ajy_test = ajy1_test\n",
    "\n",
    "vanval = run_skfold(X, y)\n",
    "ajval = run_skfold(ajX,ajy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **테스트 셋 검증**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:29:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "X, y = RandomUnderSampler(random_state=1).fit_resample(X, y)\n",
    "########################################################################################## 데이터셋 1\n",
    "dt_clf = modeling(DecisionTreeClassifier(), X, y, X_test)\n",
    "rf_clf = modeling(RandomForestClassifier(),X, y, X_test)\n",
    "ada_clf = modeling(AdaBoostClassifier(), X, y, X_test)\n",
    "lg_clf = modeling(LogisticRegression(), X, y, X_test)\n",
    "knn_clf = modeling(KNeighborsClassifier(), X, y, X_test)\n",
    "svc_clf = modeling(SVC(probability=True), X, y, X_test)\n",
    "lgmb_clf = modeling(LGBMClassifier(), X, y, X_test)\n",
    "cat_clf = modeling(CatBoostClassifier(silent=True),X, y, X_test)\n",
    "mlp_clf = modeling(MLPClassifier(),X, y, X_test)\n",
    "xgb_clf = modeling(XGBClassifier(),X, y, X_test)\n",
    "\n",
    "ajX, ajy = RandomUnderSampler(random_state=1).fit_resample(ajX, ajy)\n",
    "########################################################################################## 데이터셋 2\n",
    "ajdt_clf = modeling(DecisionTreeClassifier(), ajX, ajy, ajX_test)\n",
    "ajrf_clf = modeling(RandomForestClassifier(),ajX, ajy, ajX_test)\n",
    "ajada_clf = modeling(AdaBoostClassifier(), ajX, ajy, ajX_test)\n",
    "ajlg_clf = modeling(LogisticRegression(), ajX, ajy, ajX_test)\n",
    "ajknn_clf = modeling(KNeighborsClassifier(), ajX, ajy, ajX_test)\n",
    "ajsvc_clf = modeling(SVC(probability=True), ajX, ajy, ajX_test)\n",
    "ajlgmb_clf = modeling(LGBMClassifier(), ajX, ajy, ajX_test)\n",
    "ajcat_clf = modeling(CatBoostClassifier(silent=True),ajX, ajy, ajX_test)\n",
    "ajmlp_clf = modeling(MLPClassifier(),ajX, ajy, ajX_test)\n",
    "ajxgb_clf = modeling(XGBClassifier(),ajX, ajy, ajX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" for i in arr:\\n    print(scoring(y_test , i))\\n    print('-'*60)\\n\\nfor i in ajarr:\\n    print(scoring(y_test , i))\\n    print('-'*60) \""
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" for i in arr:\n",
    "    print(scoring(y_test , i))\n",
    "    print('-'*60)\n",
    "\n",
    "for i in ajarr:\n",
    "    print(scoring(y_test , i))\n",
    "    print('-'*60) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr =[dt_clf,rf_clf,ada_clf,lg_clf,knn_clf,svc_clf,lgmb_clf,cat_clf,mlp_clf,xgb_clf]\n",
    "ajarr = [ajdt_clf,ajrf_clf,ajada_clf,ajlg_clf,ajknn_clf,ajsvc_clf,ajlgmb_clf,ajcat_clf,ajmlp_clf,ajxgb_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc(y_true, arr_):\n",
    "    acc = []\n",
    "    for i in arr_:\n",
    "        acc.append(round(accuracy_score(y_true, i),4))\n",
    "    return acc\n",
    "\n",
    "ogntest = test_acc(y_test, arr)\n",
    "ajdtest = test_acc(ajy_test, ajarr)\n",
    "\n",
    "def get_f1(y_true, arr_):\n",
    "    f1 = []\n",
    "    for i in arr_:\n",
    "        f1.append(round(f1_score(y_true, i, average='weighted'),4))\n",
    "    return f1\n",
    "     \n",
    "ognf1 = get_f1(y_test, arr)\n",
    "ajdf1 = get_f1(ajy_test, ajarr)\n",
    "\n",
    "def get_rc(y_true, arr_):\n",
    "    rc = []\n",
    "    for i in arr_:\n",
    "        rc.append(round(recall_score(y_true, i, average='weighted'),4))\n",
    "    return rc\n",
    "\n",
    "ognrc = get_rc(y_test, arr)\n",
    "ajdrc = get_rc(ajy_test, ajarr)\n",
    "\n",
    "def get_pc(y_true, arr_):\n",
    "    pc = []\n",
    "    for i in arr_:\n",
    "        pc.append(round(precision_score(y_true, i, average='weighted'),4))\n",
    "    return pc\n",
    "\n",
    "ognpc = get_pc(y_test, arr)\n",
    "ajdpc = get_pc(ajy_test, ajarr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetone = pd.DataFrame({'model': mdn, 'SET1 val Accuracy': vanval, 'SET1 test Accuracy' : ogntest, 'SET1 test f1-Score': ognf1, 'SET1 test Precision': ognpc, 'SET1 test Recall': ognrc, \n",
    "                                        'SET2 val Accuracy' : ajval, 'SET2 test Accuracy' : ajdtest, 'SET2 test f1_Score': ajdf1, 'SET2 test Precision': ajdpc, 'SET2 test Recall': ajdrc})\n",
    "subsetone.to_csv('1년차검증.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "71b59b5ba49ad06bb2a011e750699e3983d230921f30bf7f37eb3a01ae69aa26"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
